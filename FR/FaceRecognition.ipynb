{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lavish/Documents/tensorflow3/lib/python3.5/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import load_model\n",
    "from keras.layers import Conv2D, ZeroPadding2D, Activation, Input, concatenate\n",
    "from keras.models import Model\n",
    "from keras.utils import CustomObjectScope\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers.pooling import MaxPooling2D, AveragePooling2D\n",
    "from keras.layers.merge import Concatenate\n",
    "from keras.layers.core import Lambda, Flatten, Dense\n",
    "from keras.initializers import glorot_uniform\n",
    "from keras.engine.topology import Layer\n",
    "from keras import backend as K\n",
    "K.set_image_data_format('channels_first')\n",
    "import cv2\n",
    "import h5py\n",
    "import os\n",
    "import numpy as np\n",
    "from numpy import genfromtxt\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from fr_utils import *\n",
    "from inception_blocks_v2 import *\n",
    "\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "np.set_printoptions(threshold=np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "FRmodel = faceRecoModel(input_shape=(3, 96, 96))\n",
    "for layer in FRmodel.layers:\n",
    "    layer.trainable=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Params: 3743280\n"
     ]
    }
   ],
   "source": [
    "FRmodel.get_layer('dense_layer').trainable=True\n",
    "print(\"Total Params:\", FRmodel.count_params())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GRADED FUNCTION: triplet_loss\n",
    "\n",
    "def triplet_loss(y_true, y_pred, alpha = 0.2):\n",
    "    anchor, positive, negative = y_pred[0], y_pred[1], y_pred[2]\n",
    "\n",
    "    pos_dist = tf.reduce_sum(tf.square(tf.subtract(anchor,positive)),axis=-1)\n",
    "    neg_dist = tf.reduce_sum(tf.square(tf.subtract(anchor,negative)),axis=-1)\n",
    "    basic_loss = pos_dist - neg_dist + alpha\n",
    "    \n",
    "    loss = tf.reduce_sum(tf.maximum(basic_loss,0))\n",
    "    \n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss = 528.14294\n",
      "Keys: KeysView(<HDF5 file \"train_face.h5\" (mode r)>)\n",
      "b'kian'\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as test:\n",
    "    tf.set_random_seed(1)\n",
    "    y_true = (None, None, None)\n",
    "    y_pred = (tf.random_normal([3, 128], mean=6, stddev=0.1, seed = 1),\n",
    "              tf.random_normal([3, 128], mean=1, stddev=1, seed = 1),\n",
    "              tf.random_normal([3, 128], mean=3, stddev=4, seed = 1))\n",
    "    loss = triplet_loss(y_true, y_pred)\n",
    "    \n",
    "    print(\"loss = \" + str(loss.eval()))\n",
    "f=h5py.File('datasets/train_face.h5','r')\n",
    "print(\"Keys: %s\" % f.keys())\n",
    "train_X=list(f.keys())[0]\n",
    "data = list(f[train_X])\n",
    "print(data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "FRmodel.compile(optimizer = 'adam', loss = triplet_loss, metrics = ['accuracy'])\n",
    "load_weights_from_FaceNet(FRmodel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lavish/Documents/tensorflow3/lib/python3.5/site-packages/skimage/transform/_warps.py:84: UserWarning: The default mode, 'constant', will be changed to 'reflect' in skimage 0.15.\n",
      "  warn(\"The default mode, 'constant', will be changed to 'reflect' in \"\n"
     ]
    }
   ],
   "source": [
    "database = {}\n",
    "\n",
    "for folder in os.listdir('lfw/'):\n",
    "    ln=len([name for name in os.listdir('lfw'+'/'+folder)])\n",
    "    if ln>1:\n",
    "        for file in os.listdir('lfw/'+folder):\n",
    "            file_ad = 'lfw/'+folder+'/'+file\n",
    "            database[file]=img_to_encoding2(file_ad,FRmodel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# verify\n",
    "\n",
    "def verify(image_path, identity, database, model):   \n",
    "    \n",
    "    encoding = img_to_encoding2(image_path,model)\n",
    "    # Step 2: Compute distance with identity's image (≈ 1 line)\n",
    "    dist = np.linalg.norm(encoding-database[identity])\n",
    "    # Step 3: Open the door if dist < 0.7, else don't open (≈ 3 lines)\n",
    "    if dist<0.7:\n",
    "        print(\"It's \" + str(identity) + \", welcome home!\")\n",
    "        door_open = True \n",
    "    else:\n",
    "        print(\"It's not \" + str(identity) + \", please go away\")\n",
    "        door_open = False\n",
    "        \n",
    "    ### END CODE HERE ###\n",
    "        \n",
    "    return dist, door_open\n",
    "print(os.listdir('lfw'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "verify(\"lfw/Bryan_Chui/Bryan_Chui_0001.jpg\", \"Bryan_Chui\", database, FRmodel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "verify(\"images/camera_2.jpg\", \"kian\", database, FRmodel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GRADED FUNCTION: who_is_it\n",
    "\n",
    "def who_is_it(image_path,person,database, model):   \n",
    "\n",
    "    encoding = img_to_encoding2(image_path,model)\n",
    "    \n",
    "    min_dist = 100\n",
    "    \n",
    "    for (name, db_enc) in database.items():\n",
    "        \n",
    "    \n",
    "        dist = np.linalg.norm(encoding-db_enc)\n",
    "\n",
    "    \n",
    "        if dist<min_dist:\n",
    "            min_dist = dist\n",
    "            c=0\n",
    "            for letter in name:\n",
    "                    if(letter.isdigit()):\n",
    "                        name=name[0:c-1]\n",
    "                    c+=1\n",
    "            identity = name\n",
    "\n",
    "    \n",
    "    if min_dist < 0.7 and identity==person:\n",
    "        output=1\n",
    "    else:\n",
    "        output=0\n",
    "        \n",
    "    return min_dist, output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# FUNCTION: who_is_it\n",
    "\n",
    "def who_is_it(image_path,person,database, model):   \n",
    "\n",
    "    encoding = img_to_encoding2(image_path,model)\n",
    "    \n",
    "    min_dist = 100\n",
    "    \n",
    "    for (name, db_enc) in database.items():\n",
    "        \n",
    "        dist = np.linalg.norm(encoding-db_enc)\n",
    "\n",
    "        if dist<min_dist:\n",
    "            min_dist = dist\n",
    "            c=0\n",
    "            for letter in name:\n",
    "                    if(letter.isdigit()):\n",
    "                        name=name[0:c-1]\n",
    "                    c+=1\n",
    "            identity = name\n",
    "    \n",
    "    if min_dist < 0.7 and identity==person:\n",
    "        output=1\n",
    "    else:\n",
    "        output=0\n",
    "        \n",
    "    return output,identity\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lavish/Documents/tensorflow3/lib/python3.5/site-packages/skimage/transform/_warps.py:84: UserWarning: The default mode, 'constant', will be changed to 'reflect' in skimage 0.15.\n",
      "  warn(\"The default mode, 'constant', will be changed to 'reflect' in \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100.0% is total acccuracy\n"
     ]
    }
   ],
   "source": [
    "total=0\n",
    "acc = 0\n",
    "for folder in os.listdir('lfw/'):\n",
    "    ln=len([name for name in os.listdir('lfw'+'/'+folder)])\n",
    "    if ln>1:\n",
    "        for file in os.listdir('lfw/'+folder):\n",
    "            file_ad = 'lfw/'+folder+'/'+file\n",
    "            out,identity = who_is_it(file_ad,folder,database,FRmodel)\n",
    "            total+=1\n",
    "            acc+=out\n",
    "print(str(acc*100/total)+'% is total acccuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9164\n"
     ]
    }
   ],
   "source": [
    "print(total)"
   ]
  }
 ],
 "metadata": {
  "coursera": {
   "course_slug": "convolutional-neural-networks",
   "graded_item_id": "IaknP",
   "launcher_item_id": "5UMr4"
  },
  "kernelspec": {
   "display_name": "tensorflow3",
   "language": "python",
   "name": "tensorflow3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
